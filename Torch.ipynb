{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m8r import view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file 1_train.scons \n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# fixes wierd Mac problem\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "\n",
    "import torch\n",
    "torch.manual_seed(2021) # for reproducibility\n",
    "\n",
    "import m8r\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def get_data(target=None,source=None,env=None):\n",
    "    # emits data subdirectory - clean later\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "    train_data = datasets.MNIST('./data', train=True, \n",
    "                            download=True,\n",
    "                            transform=transform)\n",
    "    test_data = datasets.MNIST('./data', train=False,\n",
    "                             download=True,\n",
    "                            transform=transform)\n",
    "    m8r.File(train_data.data.numpy(),name=str(target[0]))\n",
    "    m8r.File(train_data.targets.numpy(),name=str(target[1]))\n",
    "    m8r.File(test_data.data.numpy(),name=str(target[2]))\n",
    "    m8r.File(test_data.targets.numpy(),name=str(target[3]))\n",
    "    \n",
    "Command(['xtrain.rsf','ytrain.rsf','xtest.rsf','ytest.rsf'],None,\n",
    "       action=Action(get_data))\n",
    "\n",
    "examples = []\n",
    "for example in (10010,20010,30010,40010,50010):\n",
    "    label = 'label%d.txt' % example\n",
    "    Flow(label,'ytrain',\n",
    "         '''\n",
    "         window n1=1 f1=%d | disfil format='title=label:%%d' number=n\n",
    "         ''' % example)\n",
    "    xtrain = 'xtrain%d' % example\n",
    "    Plot(xtrain,['xtrain',label],\n",
    "         '''\n",
    "         window n3=1 f3=%d | \n",
    "         grey par=${SOURCES[1]} screenratio=1 transp=n wantaxis=n color=I titlesz=24\n",
    "         ''' % example)\n",
    "    examples.append(xtrain)\n",
    "    \n",
    "Result('train',examples,'SideBySideIso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file 2_test.scons \n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# design neural network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
    "\n",
    "def train(train_loader,epoch):\n",
    "    global model,device,optimizer\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(test_loader):\n",
    "    global model,device\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "            \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def train_model(target=None,source=None,env=None):\n",
    "    global model,device,optimizer\n",
    "    \n",
    "    x_train = torch.from_numpy(m8r.File(str(source[0]))[:])\n",
    "    y_train = torch.from_numpy(m8r.File(str(source[1]))[:])\n",
    "    x_test = torch.from_numpy(m8r.File(str(source[2]))[:])\n",
    "    y_test = torch.from_numpy(m8r.File(str(source[3]))[:])\n",
    "\n",
    "    batch_size=env.get('batch_size')\n",
    "    epochs=env.get('epochs')\n",
    "\n",
    "    x_train = x_train.unsqueeze(1)\n",
    "    train_data = TensorDataset(x_train.float(),y_train.long())\n",
    "    train_loader = DataLoader(train_data,batch_size=batch_size)\n",
    "\n",
    "    x_test = x_test.unsqueeze(1)\n",
    "    test_data = TensorDataset(x_test.float(),y_test.long())\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,batch_size=1000)\n",
    "\n",
    "    from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "    for epoch in range(1,epochs+1):\n",
    "        train(train_loader,epoch)\n",
    "        test(test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.state_dict(),str(target[0]))\n",
    "        \n",
    "Command('model.pt',['xtrain.rsf','ytrain.rsf','xtest.rsf','ytest.rsf'],\n",
    "        action=Action(train_model),\n",
    "        varlist=['batch_size','epochs'],batch_size=64,epochs=15)\n",
    "\n",
    "import keras\n",
    "\n",
    "def predict(target=None,source=None,env=None):\n",
    "    global model\n",
    "    model.load_state_dict(torch.load(str(source[0])))\n",
    "    model.eval()\n",
    "\n",
    "    x_test = torch.from_numpy(m8r.File(str(source[1]))[:])\n",
    "    x_test = x_test.unsqueeze(1)\n",
    "    y_pred = model(x_test.float())\n",
    "    m8r.File(y_pred.detach().numpy(),name=str(target[0]))\n",
    "    \n",
    "Command('ypred.rsf',['model.pt','xtest.rsf'],action=Action(predict))\n",
    "\n",
    "examples = []\n",
    "for example in (110,210,310,410,510):\n",
    "    label = 'plabel%d.txt' % example\n",
    "    Flow(label,'ypred',\n",
    "         '''\n",
    "         window n2=1 f2=%d | attr want=max | awk \\'{ printf(\\\"title=label:%%d\\n\\\",$$NF-1)}\\'\n",
    "         ''' % example)\n",
    "    xtest = 'xtest%d' % example\n",
    "    Plot(xtest,['xtest',label],\n",
    "         '''\n",
    "         window n3=1 f3=%d | \n",
    "         grey par=${SOURCES[1]} screenratio=1 transp=n wantaxis=n color=I titlesz=24\n",
    "         ''' % example)\n",
    "    examples.append(xtest)\n",
    "    \n",
    "Result('test',examples,'SideBySideIso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(\"test\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
